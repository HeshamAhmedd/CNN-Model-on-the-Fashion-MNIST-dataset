{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO93E769fnVOFPRLMxX6RtK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HeshamAhmedd/CNN-Model-on-the-Fashion-MNIST-dataset/blob/main/cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "W5XE0siyBdTL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import numpy as np\n",
        "import time\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "Ww-VQNTdBkSn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuZ0owoABq1k",
        "outputId": "8a4b8eb0-c085-4a5a-f879-5683081ae809"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Transforms and datasets\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Download datasets\n",
        "train_full = datasets.FashionMNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_set   = datasets.FashionMNIST(root=\"./data\", train=False, download=True, transform=transform)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QymbwUPzBtoc",
        "outputId": "a8c6133c-b709-4c93-c905-a97edf11385e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 18.3MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 297kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 5.45MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 14.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split train -> train/val\n",
        "train_size = len(train_full) - 10000\n",
        "val_size = 10000\n",
        "train_set, val_set = random_split(train_full, [train_size, val_size])\n",
        "\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n"
      ],
      "metadata": {
        "id": "fDAoRGZNByrU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Model\n",
        "class FashionCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # 28x28 -> 28x28\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) # -> 28x28\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool = nn.MaxPool2d(2)  # -> 14x14\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1) # -> 14x14\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.fc1 = nn.Linear(128 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool(x)  # now spatial 7x7\n",
        "        x = self.dropout(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = FashionCNN().to(device)\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivdwv8tJB336",
        "outputId": "86155b59-4f30-4045-83f5-843e38523f47"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FashionCNN(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (dropout): Dropout(p=0.25, inplace=False)\n",
            "  (fc1): Linear(in_features=6272, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',\n",
        "    factor=0.5,\n",
        "    patience=3\n",
        ")\n"
      ],
      "metadata": {
        "id": "KKZEek0ZB76l"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# utility: evaluate\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    total, correct = 0, 0\n",
        "    loss_sum = 0.0\n",
        "    with torch.no_grad():\n",
        "        for X, y in loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            logits = model(X)\n",
        "            loss = criterion(logits, y)\n",
        "            loss_sum += loss.item() * X.size(0)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    return loss_sum / total, correct / total\n"
      ],
      "metadata": {
        "id": "TvW16-ZICIH_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Performance settings\n",
        "torch.backends.cudnn.benchmark = True   # good for fixed input sizes\n",
        "# If you want to limit CPU threads (helpful on some systems)\n",
        "# import os\n",
        "# torch.set_num_threads(4)\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n",
        "\n",
        "epochs = 12                # reduce epochs to start\n",
        "best_val_acc = 0.0\n",
        "batch_size = 256           # increase if GPU memory allows\n",
        "\n",
        "# (Recreate DataLoaders if changing batch_size / num_workers)\n",
        "# train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=6, pin_memory=True)\n",
        "# val_loader   = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=6, pin_memory=True)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    epoch_start = time.time()\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    num_samples = 0\n",
        "\n",
        "    # training loop with AMP\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\", leave=False)\n",
        "    for X, y in loop:\n",
        "        X = X.to(device, non_blocking=True)\n",
        "        y = y.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        if scaler is not None:\n",
        "            with torch.cuda.amp.autocast():\n",
        "                logits = model(X)\n",
        "                loss = criterion(logits, y)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            logits = model(X)\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        batch_size_curr = X.size(0)\n",
        "        running_loss += loss.item() * batch_size_curr\n",
        "        num_samples += batch_size_curr\n",
        "\n",
        "        loop.set_postfix(loss=(running_loss / num_samples))\n",
        "\n",
        "    train_loss = running_loss / num_samples\n",
        "\n",
        "    # validation (no grad)\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for Xv, yv in val_loader:\n",
        "            Xv = Xv.to(device, non_blocking=True)\n",
        "            yv = yv.to(device, non_blocking=True)\n",
        "            if scaler is not None:\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    logits = model(Xv)\n",
        "                    lossv = criterion(logits, yv)\n",
        "            else:\n",
        "                logits = model(Xv)\n",
        "                lossv = criterion(logits, yv)\n",
        "\n",
        "            val_loss += lossv.item() * Xv.size(0)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct += (preds == yv).sum().item()\n",
        "            total += yv.size(0)\n",
        "\n",
        "    val_loss = val_loss / total\n",
        "    val_acc = correct / total\n",
        "\n",
        "    # LR scheduler step (ReduceLROnPlateau expects validation metric)\n",
        "    old_lr = optimizer.param_groups[0]['lr']\n",
        "    scheduler.step(val_loss)\n",
        "    new_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "    if new_lr != old_lr:\n",
        "        print(f\"LR reduced from {old_lr:.2e} to {new_lr:.2e}\")\n",
        "\n",
        "    epoch_time = time.time() - epoch_start\n",
        "    print(f\"Epoch {epoch:02d} | Train loss: {train_loss:.4f} | Val loss: {val_loss:.4f} | Val acc: {val_acc:.4f} | {epoch_time:.1f}s\")\n",
        "\n",
        "    # Save best\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), \"fashion_cnn_pytorch_best.pth\")\n",
        "        print(\" Saved best model.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEo6AH73CO5N",
        "outputId": "8847f3f3-d6e2-475b-861c-91cbc0943cdd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | Train loss: 0.2459 | Val loss: 0.2237 | Val acc: 0.9182 | 277.0s\n",
            " Saved best model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 02 | Train loss: 0.2208 | Val loss: 0.2204 | Val acc: 0.9217 | 272.0s\n",
            " Saved best model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 03 | Train loss: 0.2030 | Val loss: 0.1983 | Val acc: 0.9270 | 275.4s\n",
            " Saved best model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 04 | Train loss: 0.1935 | Val loss: 0.1940 | Val acc: 0.9305 | 277.1s\n",
            " Saved best model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 05 | Train loss: 0.1767 | Val loss: 0.1940 | Val acc: 0.9302 | 271.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 06 | Train loss: 0.1637 | Val loss: 0.1995 | Val acc: 0.9296 | 270.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 07 | Train loss: 0.1557 | Val loss: 0.1913 | Val acc: 0.9324 | 270.7s\n",
            " Saved best model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 08 | Train loss: 0.1466 | Val loss: 0.1866 | Val acc: 0.9323 | 270.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 09 | Train loss: 0.1370 | Val loss: 0.1944 | Val acc: 0.9325 | 272.3s\n",
            " Saved best model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 | Train loss: 0.1300 | Val loss: 0.2009 | Val acc: 0.9310 | 274.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 | Train loss: 0.1254 | Val loss: 0.1884 | Val acc: 0.9355 | 272.8s\n",
            " Saved best model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR reduced from 1.00e-03 to 5.00e-04\n",
            "Epoch 12 | Train loss: 0.1202 | Val loss: 0.1954 | Val acc: 0.9341 | 279.4s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) Final test evaluation\n",
        "model.load_state_dict(torch.load(\"fashion_cnn_pytorch_best.pth\"))\n",
        "test_loss, test_acc = evaluate(test_loader)\n",
        "print(f\"PyTorch test loss: {test_loss:.4f}, test accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPMThtlnEDNO",
        "outputId": "dc0ac52f-3ed9-4900-cbba-1f56a7a0c706"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch test loss: 0.2122, test accuracy: 0.9310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) Sample predictions\n",
        "classes = ['T-shirt/top','Trouser','Pullover','Dress','Coat',\n",
        "           'Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
        "\n",
        "model.eval()\n",
        "batch = next(iter(test_loader))\n",
        "X_sample, y_sample = batch[0][:9].to(device), batch[1][:9].to(device)\n",
        "with torch.no_grad():\n",
        "    logits = model(X_sample)\n",
        "    preds = logits.argmax(dim=1)\n",
        "for i in range(len(preds)):\n",
        "    print(i, \"pred:\", preds[i].item(), classes[preds[i].item()], \"true:\", y_sample[i].item(), classes[y_sample[i].item()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A1VUPzxPAuq",
        "outputId": "668ca57b-9f37-43fd-9e39-a1035564e6d0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 pred: 9 Ankle boot true: 9 Ankle boot\n",
            "1 pred: 2 Pullover true: 2 Pullover\n",
            "2 pred: 1 Trouser true: 1 Trouser\n",
            "3 pred: 1 Trouser true: 1 Trouser\n",
            "4 pred: 6 Shirt true: 6 Shirt\n",
            "5 pred: 1 Trouser true: 1 Trouser\n",
            "6 pred: 4 Coat true: 4 Coat\n",
            "7 pred: 6 Shirt true: 6 Shirt\n",
            "8 pred: 5 Sandal true: 5 Sandal\n"
          ]
        }
      ]
    }
  ]
}